#https://stats.stackexchange.com/questions/108834/calculate-coefficients-in-a-ordinal-logistic-regression-with-r
import pandas as pd
import numpy as np
X = pd.read_csv("C:\\Users\\enisbe\\Documents\\jupyter\\data\\X.csv")
y = pd.read_csv("C:\\Users\\enisbe\\Documents\\jupyter\\data\\y.csv")
start = pd.read_csv("C:\\Users\\enisbe\\Documents\\jupyter\\data\\start.csv")
X = X.iloc[:,1:].to_numpy()
y  = np.ravel(  y.iloc[:,1:].to_numpy())
s0 =start.iloc[:,1:].to_numpy()
np.set_printoptions(precision=4)
#
# X['t'] = y
# y.shape
# X.shape
# X.head()
# X["y"] = y
#
# X.head()
# X.to_csv("C:\\Users\\enisbe\\Documents\\jupyter\\data\\X_all.csv")
#
X_new = X[:,0:2]



def cdf1(X):
    X = np.asarray(X)
    return 1 / (1 + np.exp(-X))


def cdf2(X):
    X = np.asarray(X)
    return 1 / (1 + np.exp(X))


def loglike(theta, x,y):



    t1  = theta[0]
    t2  = theta[1]
    t3  = theta[2]
    b  =  theta[3:]
    cdfL = []

    cdf = cdf2
    cdfL.append([cdf(np.dot(x, b) - t1)])
    cdfL.append([cdf(np.dot(x, b) - t2)])
    cdfL.append([cdf(np.dot(x, b) - t3)])


    one = np.vstack((np.log(cdfL[0][0] - 0), y)).T
    two = np.vstack((np.log(cdfL[1][0] - cdfL[0][0]), y)).T
    three = np.vstack((np.log(cdfL[2][0] - cdfL[1][0]), y)).T
    four = np.vstack((np.log(1 - cdfL[2][0]), y)).T

    one < - np.vstack((np.log(1 / (1 + np.exp(np.dot(x, b) - t1)) - 0), y)).T
    two < - np.vstack((np.log(1 / (1+ np.exp(np.dot(x, b) - t2)) - 1 / (1+ np.exp(np.dot(x, b) - t2))), y)).T
    three < -  np.vstack((np.log(1 / (1+ np.exp(np.dot(x, b) - t3)) - 1 / (1+ np.exp(np.dot(x, b) - t2))), y)).T
    four < - np.vstack((np.log(1 - 1 / (1 + np.exp(np.dot(x, b) - t3))), y)).T

    ll = np.sum(one[one[:,1]==1][:,0]) + np.sum(two[two[:,1]==2][:,0]) + np.sum(three[three[:,1]==3][:,0]) +np.sum(four[four[:,1]==4][:,0])

    return -ll

print(loglike(theta0, X_new, y))

def loglike2(theta, x, y):
    a1 = theta[0]
    a2 = theta[1]
    a3 = theta[2]
    b = theta[3:]

    cdf = cdf2

    XB = np.dot(x, b)

    y_eq_1 = np.log(cdf(-(a1 + XB)))
    y_eq_2 = np.log(cdf(-(a2 + XB)) - cdf(-(a1 + XB)))
    y_eq_3 = np.log(cdf(-(a3 + XB)) - cdf(-(a2 + XB)))
    y_eq_4 = np.log(1 - cdf(-(a3 + XB)))

    ll = np.sum(y_eq_1[y == 1]) + np.sum(y_eq_2[y == 2]) + np.sum(y_eq_3[y == 3]) + np.sum(y_eq_4[y == 4])
    return -ll

print(loglike2(theta0, X_new, y))

print(loglike(theta0, X_new, y))



classes_ = np.unique(y)
n_class_ = classes_.max() - classes_.min() + 1

from scipy.optimize import minimize
ui = list([[-1, 1, 0, 0, 0], [0, -1, 1, 0, 0], [-1, 0, 1, 0, 0]])
ui = list([[-1, 1, 0, 0, 0], [0, -1, 1, 0, 0], [-1, 0, 1, 0, 0]])

ci =  np.array([1,1,1])
theta0 = np.array([-2,1,4,1,-1])

options = {'maxiter': 10000, 'disp': False}
n_samples, n_features = X_new.shape
n_class = n_class_
bounds = [(None, None)] * (n_features + 1) + [(0, None)] * (n_class - 2)

bounds = [(-1,1)] * (n_features + 1) + [(0, None)] * (n_class - 2)

np.asarray(bounds)
minimize(loglike2, theta0,args=(X_new,y) ,method='L-BFGS-B',  bounds=ui, options=options)['x']
minimize(loglike, theta0,args=(X_new,y) ,method='L-BFGS-B',  bounds=ui, options=options)['x']

minimize(loglike, theta0,args=(X_new,y) ,method='L-BFGS-B')['x']
minimize(loglike2, theta0,args=(X_new,y) ,method='L-BFGS-B')['x']
minimize(loglike2, theta0,args=(X_new,y) ,method='BFGS', options={'gtol':1e-2})['x']

print(res)
options = {'maxiter': max_iter, 'disp': verbose}



constraints = c_, bounds = b_,
a = fmin_bfgs(loglike,theta0,args=(X_new,y)  )

# n_vars = x.shape[1]
# n_params = theta0.shape[0]-1
# n_intercept = n_params - n_vars +1

# var_ll = []
# for i in n_params:
# var_ll.append(np.vstack((np.log(cdfL[0][0]-0) ,y)).T)
# var_ll.append(np.vstack((np.log(cdfL[1][0] - cdfL[0][0]),y)).T
# var[2] = np.vstack((np.log(cdfL[2][0] - cdfL[1][0]),y)).T
# var[3] = np.vstack((np.log(1 - cdfL[2][0]),y)).T


val = 0.0
for i in range(4):

    response = i+1
    val += np.sum(one[one[:,1]==response][:,0] )
    print(val)









ui = np.array([[-1, 1, 0, 0, 0], [0, -1, 1, 0, 0], [-1, 0, 1, 0, 0]])
ci =  np.array([1,1,1])

np.unique(y)
